import gradio as gr
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import os

MODEL_PATH = "./models/spam_model"

if not os.path.exists(MODEL_PATH):
    raise RuntimeError(
        "–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞! –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –µ—ë —Å –ø–æ–º–æ—â—å—é:\n"
        "python scripts/project2_spam.py"
    )

tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)
model.eval()
device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)

def classify_spam(text: str) -> dict:
    if not text.strip():
        return {"NOT SPAM": 0.5, "SPAM": 0.5}
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=256).to(device)
    with torch.no_grad():
        logits = model(**inputs).logits
    probs = torch.softmax(logits, dim=-1)[0]
    return {
        "NOT SPAM": float(probs[0]),
        "SPAM": float(probs[1])
    }

gr.Interface(
    fn=classify_spam,
    inputs=gr.Textbox(
        lines=3,
        placeholder="–í–≤–µ–¥–∏—Ç–µ SMS –∏–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ...",
        label="–¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è"
    ),
    outputs=gr.Label(num_top_classes=2),
    title="üá∑üá∫ –°–ø–∞–º-–¥–µ—Ç–µ–∫—Ç–æ—Ä (RuBERT-tiny)",
    description="–ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ –Ω–µ–±–æ–ª—å—à–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ. –î–ª—è —É—á–µ–±–Ω—ã—Ö —Ü–µ–ª–µ–π.",
    examples=[
        ["–í—ã –≤—ã–∏–≥—Ä–∞–ª–∏ 1 000 000 —Ä—É–±–ª–µ–π! –ü–µ—Ä–µ–π–¥–∏—Ç–µ –ø–æ —Å—Å—ã–ª–∫–µ!"],
        ["–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞? –í—Å—Ç—Ä–µ—á–∞–µ–º—Å—è —Å–µ–≥–æ–¥–Ω—è –≤ 18:00?"]
    ],
    live=False
).launch()  # ‚Üê –í Colab –∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ .launch(share=True)