import gradio as gr
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import os

MODEL_PATH = "./models/sentiment_model"

if not os.path.exists(MODEL_PATH):
    raise RuntimeError(
        "–ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞! –°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –µ—ë —Å –ø–æ–º–æ—â—å—é:\n"
        "python scripts/project1_sentiment.py"
    )

tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)
model.eval()
device = "cuda" if torch.cuda.is_available() else "cpu"
model.to(device)

def classify_sentiment(text: str) -> dict:
    if not text.strip():
        return {"NEGATIVE": 0.5, "POSITIVE": 0.5}
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=256).to(device)
    with torch.no_grad():
        logits = model(**inputs).logits
    probs = torch.softmax(logits, dim=-1)[0]
    return {
        "NEGATIVE": float(probs[0]),
        "POSITIVE": float(probs[1])
    }

gr.Interface(
    fn=classify_sentiment,
    inputs=gr.Textbox(
        lines=3,
        placeholder="–í–≤–µ–¥–∏—Ç–µ –æ—Ç–∑—ã–≤ –∏–ª–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π...",
        label="–¢–µ–∫—Å—Ç"
    ),
    outputs=gr.Label(num_top_classes=2),
    title="üá∑üá∫ –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ (RuBERT-tiny)",
    description="–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ç–µ–∫—Å—Ç –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–º –∏–ª–∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–º.",
    examples=[
        ["–û—Ç–ª–∏—á–Ω—ã–π —Ñ–∏–ª—å–º! –ê–∫—Ç—ë—Ä—ã –∏–≥—Ä–∞—é—Ç –≤–µ–ª–∏–∫–æ–ª–µ–ø–Ω–æ."],
        ["–£–∂–∞—Å–Ω–æ–µ –∫–∏–Ω–æ, –∑—Ä—è –ø–æ—Ç—Ä–∞—Ç–∏–ª –≤—Ä–µ–º—è."]
    ],
    live=False
).launch()  # ‚Üê –í Colab –∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ .launch(share=True)